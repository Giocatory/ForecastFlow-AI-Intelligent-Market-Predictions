from autots import AutoTS
import pandas as pd
import streamlit as st
import numpy as np
import logging
from datetime import datetime, timedelta

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class UniversalForecastModel:
    def __init__(self, forecast_length=12, frequency='ME', model_complexity='medium'):
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        self.forecast_length = forecast_length
        self.frequency = frequency
        self.model_complexity = model_complexity
        self.model = None
        self.best_model_name = None
        self.training_successful = False
        self.historical_data = None
        
    def prepare_data(self, data, value_column, date_column='date'):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è AutoTS"""
        try:
            df = data.copy()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—É
            df[date_column] = pd.to_datetime(df[date_column])
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –¥–∞—Ç
            df = df.drop_duplicates(subset=[date_column])
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
            df = df.sort_values(date_column)
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞—Ç—É –∫–∞–∫ –∏–Ω–¥–µ–∫—Å
            df = df.set_index(date_column)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
            if len(df) < 6:
                st.warning(f"‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(df)} —Ç–æ—á–µ–∫. –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 6.")
                return None
            
            # –í—ã–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            if value_column not in df.columns:
                st.error(f"–ö–æ–ª–æ–Ω–∫–∞ '{value_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
                return None
                
            ts_data = df[[value_column]]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
            self.historical_data = ts_data.copy()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏
            if ts_data[value_column].isnull().any():
                st.warning("‚ö†Ô∏è –í –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –ó–∞–ø–æ–ª–Ω—è–µ–º –ª–∏–Ω–µ–π–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–µ–π.")
                ts_data[value_column] = ts_data[value_column].interpolate()
            
            return ts_data
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
            return None
    
    def get_model_list(self, data_length):
        """–í—ã–±–æ—Ä —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö"""
        
        if self.model_complexity == 'simple':
            return 'superfast'  # –°–∞–º—ã–µ –±—ã—Å—Ç—Ä—ã–µ –∏ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
        
        elif self.model_complexity == 'medium':
            return 'fast'  # –ë—ã—Å—Ç—Ä—ã–µ –º–æ–¥–µ–ª–∏
        
        elif self.model_complexity == 'complex':
            return 'default'  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –Ω–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π
        
        else:  # 'all'
            return 'all'  # –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
    
    def train(self, data, value_column):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø–µ—Ä–µ–±–æ—Ä–æ–º –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            ts_data = self.prepare_data(data, value_column)
            if ts_data is None:
                return False
            
            data_length = len(ts_data)
            
            # –í—ã–±–æ—Ä —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
            model_list = self.get_model_list(data_length)
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ AutoTS –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö
            if data_length <= 12:
                generations = 1
                validations = 1
            elif data_length <= 24:
                generations = 2
                validations = 2
            else:
                generations = 3
                validations = 3
            
            st.info(f"""
            **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è:**
            - –¢–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö: {data_length}
            - –°–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π: {self.model_complexity}
            - –ü–æ–∫–æ–ª–µ–Ω–∏–π: {generations}
            - –í–∞–ª–∏–¥–∞—Ü–∏–π: {validations}
            """)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ AutoTS
            model = AutoTS(
                forecast_length=self.forecast_length,
                frequency=self.frequency,
                model_list=model_list,
                ensemble='simple',
                max_generations=generations,
                num_validations=validations,
                validation_method='backwards',
                no_negatives=True,
                constraint=2.0,
                drop_most_recent=0,
                verbose=0
            )
            
            with st.spinner("üîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç"):
                self.model = model.fit(ts_data)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
            if (hasattr(self.model, 'best_model_name') and 
                self.model.best_model_name and 
                self.model.best_model_name != 'ZeroesNaive'):
                
                self.best_model_name = self.model.best_model_name
                self.training_successful = True
                
                st.success(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞! –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: **{self.best_model_name}**")
                
                return True
            else:
                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –ø–æ–¥—Ö–æ–¥—è—â—É—é –º–æ–¥–µ–ª—å")
                return self._train_simple_fallback(ts_data)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {str(e)}")
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
            return self._train_simple_fallback(data, value_column)
    
    def _train_simple_fallback(self, data, value_column=None):
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è —Å –ø—Ä–æ—Å—Ç—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"""
        try:
            st.info("üîÑ –ü—Ä–æ–±—É–µ–º –æ–±—É—á–∏—Ç—å —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
            
            if value_column:
                ts_data = self.prepare_data(data, value_column)
            else:
                ts_data = data
            
            if ts_data is None:
                return False
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
            simple_model = AutoTS(
                forecast_length=self.forecast_length,
                frequency=self.frequency,
                model_list=['LastValueNaive', 'AverageValueNaive', 'ETS', 'ARIMA'],
                ensemble=None,
                max_generations=1,
                num_validations=1,
                verbose=0
            )
            
            self.model = simple_model.fit(ts_data)
            
            if (hasattr(self.model, 'best_model_name') and 
                self.model.best_model_name):
                
                self.best_model_name = self.model.best_model_name + " (fallback)"
                self.training_successful = True
                st.success(f"‚úÖ –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞: **{self.best_model_name}**")
                return True
            else:
                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –¥–∞–∂–µ —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å")
                return False
                
        except Exception as e:
            st.error(f"‚ùå –†–µ–∑–µ—Ä–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ç–∞–∫–∂–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {str(e)}")
            return False
    
    def predict(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
        if not self.training_successful or self.model is None:
            st.error("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –Ω–µ –±—ã–ª–æ —É—Å–ø–µ—à–Ω—ã–º")
            return self._simple_trend_forecast()
        
        try:
            with st.spinner("üìä –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞..."):
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –æ—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                if hasattr(self.model, 'predict'):
                    forecast = self.model.predict()
                    if forecast is not None and hasattr(forecast, 'forecast'):
                        return forecast.forecast
                
                # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥
                st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –æ—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥.")
                return self._simple_trend_forecast()
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)}")
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞: {str(e)}")
            return self._simple_trend_forecast()
    
    def _simple_trend_forecast(self):
        """–ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞"""
        try:
            if self.historical_data is None:
                st.error("‚ùå –ù–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞")
                return None
            
            historical_data = self.historical_data
            values = historical_data.iloc[:, 0].values
            
            if len(values) < 2:
                # –ï—Å–ª–∏ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                last_value = values[-1]
                forecast_values = [last_value] * self.forecast_length
            else:
                # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è —Ç—Ä–µ–Ω–¥–∞
                x = np.arange(len(values))
                slope, intercept = np.polyfit(x, values, 1)
                
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–∞
                future_x = np.arange(len(values), len(values) + self.forecast_length)
                forecast_values = slope * future_x + intercept
            
            # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç—ã –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
            last_date = historical_data.index[-1]
            
            if self.frequency == 'D':
                dates = pd.date_range(start=last_date + timedelta(days=1), 
                                    periods=self.forecast_length, freq='D')
            elif self.frequency == 'ME':
                dates = pd.date_range(start=last_date + pd.offsets.MonthBegin(1), 
                                    periods=self.forecast_length, freq='ME')
            else:
                dates = pd.date_range(start=last_date + timedelta(days=30), 
                                    periods=self.forecast_length, freq=self.frequency)
            
            # –°–æ–∑–¥–∞–µ–º DataFrame —Å –ø—Ä–æ–≥–Ω–æ–∑–æ–º
            forecast_df = pd.DataFrame(
                forecast_values,
                index=dates,
                columns=['forecast_trend']
            )
            
            st.info("üìà –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞")
            return forecast_df
            
        except Exception as e:
            st.error(f"‚ùå –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥–Ω–æ–∑ —Ç–∞–∫–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {str(e)}")
            return None
    
    def get_model_info(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if not self.training_successful:
            return {
                'status': '–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ',
                'best_model': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                'forecast_length': self.forecast_length,
                'model_complexity': self.model_complexity
            }
        
        info = {
            'status': '–û–±—É—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ',
            'best_model': self.best_model_name,
            'forecast_length': self.forecast_length,
            'frequency': self.frequency,
            'model_complexity': self.model_complexity
        }
        
        try:
            if hasattr(self.model, 'validation_results') and len(self.model.validation_results) > 0:
                best_score = self.model.validation_results.iloc[0]['Score']
                info['best_score'] = f"{best_score:.2f}"
                info['models_tested'] = len(self.model.validation_results)
        except:
            pass
            
        return info

def create_forecast(data, value_column, forecast_months, model_complexity='medium', frequency='ME'):
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞
    """
    model = UniversalForecastModel(
        forecast_length=forecast_months,
        frequency=frequency,
        model_complexity=model_complexity
    )
    
    success = model.train(data, value_column)
    
    if success:
        forecast = model.predict()
        return forecast, model, True
    else:
        # –í—Å–µ —Ä–∞–≤–Ω–æ –ø—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥–Ω–æ–∑
        forecast = model._simple_trend_forecast()
        return forecast, model, forecast is not None

# –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
def create_apartment_forecast(data, forecast_months, model_complexity='medium'):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è —Ü–µ–Ω –Ω–∞ –∫–≤–∞—Ä—Ç–∏—Ä—ã"""
    return create_forecast(data, 'price', forecast_months, model_complexity, 'ME')

def create_salary_forecast(data, forecast_months, model_complexity='medium'):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è –∑–∞—Ä–ø–ª–∞—Ç"""
    return create_forecast(data, 'salary', forecast_months, model_complexity, 'ME')